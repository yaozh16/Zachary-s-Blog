# Android学习笔记(4) 学习百度语音识别SDK使用(1)

## 目录
<table>
	<th>使用</th>
	<tr><td>[初始化](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#1初始化)</td></tr>
	<tr><td>[注册自己的输出事件类](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#2注册自己的输出事件类)</td></tr>
	<tr><td>[向SDK发送开始事件](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#3向SDK发送开始事件)</td></tr>
	<tr><td>[回调事件](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#4回调事件)</td></tr>
	<tr><td>[事件管理器退出](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#5事件管理器退出)</td></tr>
	<tr><td>[离线命令词](https://github.com/yaozh16/Zachary-s-Blog/new/master/ARTICLE#6离线命令词)</td></tr>
</table>

## 1、初始化
SDK 中，通过工厂创建语音识别的事件管理器。
注意识别事件管理器只能维持一个，请勿同时使用多个实例。
即创建一个新的识别事件管理器后，之前的那个设置为null。并不再使用。

```java
EventManager asr = EventManagerFactory.create(this, "asr"); // this是Activity或其它Context类
```

## 2、注册自己的输出事件类

SDK 中，需要实现EventListener的输出事件回调接口。该类需要处理SDK在识别过程中的回调事件。
```java
EventListener yourListener = new EventListener() {
  @Override
  public void onEvent(String name, String params, byte[] data, int offset, int length) {
    if(name.equals(SpeechConstant.CALLBACK_EVENT_ASR_READY)){
    // 引擎就绪，可以说话，一般在收到此事件后通过UI通知用户可以说话了
    }
    if(name.equals(SpeechConstant.CALLBACK_EVENT_ASR_FINISH)){
    // 识别结束
    }
  // ... 支持的输出事件和事件支持的事件参数见“输入和输出参数”一节
  }
};
asr.registerListener(yourListener);
```

## 3、向SDK发送开始事件
开始事件的参数可以参见” 输入和输出参数 “。

SDK中，您需要根据文档或者demo确定您的输入参数。

DEMO中有UI界面简化选择和测试过程。demo中，在点击“开始录音”按钮后，您可以在界面或者日志中看见ASR_START事件的json格式的参数。

```java
// asr params(反馈请带上此行日志):
//{"accept-audio-data":false,"disable-punctuation":false,"accept-audio-volume":true,"pid":1736}
// 其中
//{"accept-audio-data":false,"disable-punctuation":false,"accept-audio-volume":true,"pid":1736}为ASR_START 事件的参数
String json = "{\"accept-audio-data\":false,
                \"disable-punctuation\":false,
                \"accept-audio-volume\":true,
                \"pid\":1736}";
asr.send(SpeechConstant.ASR_START, json, null, 0, 0);
```
实际上asr.send的参数为(String s,String s1,byte[],int i, int i1)
```java
//所以还可以这样:先写成HashMap再转为json String
Map<String, Object> params = new LinkedHashMap<String, Object>();
params.put(SpeechConstant.ACCEPT_AUDIO_VOLUME, false);
params.put(SpeechConstant.VAD,SpeechConstant.VAD_DNN);
params.put(SpeechConstant.DECODER, 2);
asr.send(event, new JSONObject(params).toString(), null, 0, 0);
```

### 4、回调事件
SDK中，回调事件在您实现的EventListener中获取。
```
@Override
public void onEvent(String name, String params, byte[] data, int offset, int length)
```
OnEvent中， name是输出事件名，params该事件的参数，(data,offset, length) 三者一起组成额外数据。

如回调的音频数据，从data[offset] 开始至data[offset + length] 结束，长度为length。

### 5、事件管理器退出
SDK中 无需调用任何逻辑，但需要创建一个新的识别事件管理器(EventListener)的话，之前的那个请设置为null，并不再使用。
```java
asr.send(SpeechConstant.ASR_STOP, null, null, 0, 0);
```

### 6、离线命令词
离线命令词功能需要首先实现之前的在线识别功能的代码。
离线引擎加载需要在EventManager初始化之后，识别事件之前。
在SDK中，
```java
HashMap map = new HashMap();
map.put(SpeechConstant.DECODER, 0); // 0:在线 2.离在线融合(在线优先)
map.put(SpeechConstant.ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH, "/sdcard/yourpath/baidu_speech_grammar.bsg"); // 设置离线命令词文件路径
// 下面这段可选，用于生成SLOT_DATA参数， 用于动态覆盖ASR_OFFLINE_ENGINE_GRAMMER_FILE_PATH文件的词条部分
JSONObject  json = new JSONObject();    
json.put("name", new JSONArray().put("王自强").put("叶问"));
json.put("appname", new JSONArray().put("手百").put("度秘"));        
map.put(SpeechConstant.SLOT_DATA, json.toString());
// SLOT_DATA 参数添加完毕
// 加载离线引擎，使用离线命令词时使用，请在整个离线识别任务结束之后卸载离线引擎 
asr.send(SpeechConstant.ASR_KWS_LOAD_ENGINE,new JSONObject(map).toString()); 
// 此处开始你的识别流程，注意离线必须断网生效或者SDK无法连接百度服务器时生效，只能识别bsg文件里定义的短语。

// 不再需要识别功能后，卸载离线引擎。再次需要识别功能的话，可以重复以上步骤。即依旧需要EventManager初始化之后，识别事件之前加载离线引擎。
asr.send(SpeechConstant.ASR_KWS_UNLOAD_ENGINE, null, null, 0, 0);
```
